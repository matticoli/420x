<!doctype html>
<html lang='en'>
<head>
    <style>
    body { 
        margin:0;
        font-family: Arial, Helvetica, sans-serif;
        color: white;
        background-color: #222222;
    }

    .slider {
        position: relative; 
        top: 8px;
    }

    .slider-container {
        display: inline-block; 
        padding: 5px;
    }
    td {
        padding: 20px;
    }

    .textCol {
        vertical-align: top;
        margin-left: 20px;
    }

    .nav {
        background-color: rgb(91, 83, 115);
        height: 5vh;
        padding: 5px;
        vertical-align: center;
    }

    .nav a {
        color: whitesmoke;
        display: block;
        width: 100%;
        text-decoration: none;;
        height: 10px;
        margin-top: calc(2.5vh - 7.5px);
        font-family: Arial, Helvetica, sans-serif;
    }
    </style>
</head>
<body>
    <div class="nav">
        <a href="./index.html"><b>< 420x Home</b></a>
    </div>
    <table>
        <tr>
            <td >
                <canvas id='gl'></canvas>
            </td>
            <td>
            <br/>
            <button onclick="getVideo()">Video</button>
            <button onclick="stopVideo()">Stop Video</button>
            <!-- <button onclick="initAudio()">Audio</button>
            <button onclick="() => {console.log(analyser.get(frequencyData))}">AudioDebug</button> -->
            <br/>
            <div class="slider-container">
                <label for="audiox">Audio X Effect</label>
                <input type="range" min="0" max="100" value="0" class="slider" id="audiox">
            </div>
            <br/>
            <div class="slider-container">
                <label for="audioy">Audio Y Effect</label>
                <input type="range" min="0" max="100" value="0" class="slider" id="audioy">
            </div>
            <!-- <div class="slider-container">
                <label for="cinvert">Invert Color</label>
                <input type="checkbox" id="cinvert">
            </div> -->
            <br />
            <div style="display: inline-block">
                <audio controls id="myAudio" src="./assets/GranBatalla.mp3" type="audio/mpeg"></audio>
                <span id="audioInfo"></span>
                <br />
                <i>Track: Gran Batalla by Matthew Pablo</i>
                <hr />
            </div>
            <br />
            <div class="slider-container">
                <label for="exposure">Exposure</label>
                <input type="range" min="0" max="300" value="0" class="slider" id="exposure">
            </div>
            <br />
            <div class="slider-container">
                <label for="brightness">Brightness</label>
                <input type="range" min="-100" max="300" value="0" class="slider" id="brightness">
                <label for="invert">Invert</label>
                <input type="checkbox" id="invert">
            </div>
            <br />
            <div class="slider-container">
                <label for="sinx">Sin X</label>
                <input type="range" min="-256" max="256" value="1" class="slider" id="sinx">
                <label for="xsync">Sync</label>
                <input type="checkbox" id="xsync" checked="true">
                <br />
                <label for="fx">Frequency X</label>
                <input type="range" min="1" max="10" value="1" class="slider" id="fx">
                <!-- <button onclick="document.getElementById('fx').value = 1">Zero</button> -->
            </div>
            <br />
            <div class="slider-container">
                <label for="siny">Sin Y</label>
                <input type="range" min="-256" max="256" value="1" class="slider" id="siny">
                <label for="ysync">Sync</label>
                <input type="checkbox" id="ysync" checked="true">
                <br />
                <label for="fy">Frequency Y</label>
                <input type="range" min="1" max="10" value="1" class="slider" id="fy">
            </div>
            <br />
            <div class="slider-container">
                <hr />
                <label for="colorize">Colorize</label>
                <input type="checkbox" id="colorize">
                <br />
                <label for="red">R</label>
                <input type="range" min="0" max="256" value="1" class="slider" id="red">
                <br />
                <label for="green">G</label>
                <input type="range" min="0" max="256" value="1" class="slider" id="green">
                <br />
                <label for="blue">B</label>
                <input type="range" min="0" max="256" value="1" class="slider" id="blue">
                <br />
            </div>
        </td>
        <td class="textCol">
            <h1>Vidiot Simulation</h1>
            <h3>Demo</h3>
            <iframe width="400" height="200" src="https://www.youtube.com/embed/4Y9U5CwoIUk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <h3>Reference</h3>
            <iframe width="400" height="200" src="https://www.youtube.com/embed/ccGexRnQXuw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <br />
            <a href="https://photos.app.goo.gl/B7h47fJPFZUeCxt49"><button style="font-size: 1.1em" >Click here for all vidiot experiment photos/videos</button></a>
        </td>
       </tr>
    </table>
    <div style="padding-left: 4vw; padding-right: 4vw;">
        <h3>Aesthetic and Feedback</h3>
        <p>
        My primary goal when developing the UI was to emulate the basic features of crossing vertical and horizontal lines, sync, and color with audio and video input. While experimenting with the vidiot, we found one of the most enjoyable aspects to be patching in music and seeing how the visuals reacted to different tracks. While relatively simple, the shader allows for a wide range of visuals using just vertical and horizontal bars scrolling across the screen. These are layered over the webcam video feed, with distortion added in reaction to the music based on basic fft analysis and a weighted average of the initial x/y value with the sine of the coordinate multiplied by the frequency from the audio analyser at the given time. The result is <a href="https://i.gyazo.com/dae9acc0081d7a64287dffb885dde489.mp4" style="color: whitesmoke">some cool visual effects in time with the music.</a>
        </p>
        <p>
            Upon showing the demo to a classmate, I got the following feedback:
            <ul>
                <li>Really nice clean grid pattern at beginning</li>
                <li>I like how clear the rgb controls and effects are on the animation</li>
                <li>Damn how'd you manage to get audio working?</li>
                <li>The effect of audio on the animation is very satisfying</li>
                <li>Overall you had a wide spread of controls and ways to play around </li>
                <li>With the shader which i thought was very cool</li>
                <li>The distortion around 2:45 was very interseting looking - I liked how it was asymmetrical</li>
            </ul>
            Overall, I think this was a successful attempt at emulating the experience of using the basic dials on the vidiot to make some cool audio-synced effects.
                
        </p>
        <video src="https://i.gyazo.com/dae9acc0081d7a64287dffb885dde489.mp4" crossorigin="anonymous"></video>
    </div>
</body>
<!-- vertex shader, as simple as possible -->
<script id='vertex' type='x-shader/x-vertex'>
    attribute vec2 a_position;
    void main() {
        gl_Position = vec4( a_position, 0., 1. );
    }
</script>
<!-- fragment shader -->
<script id='fragment' type='x-shader/x-fragment'>
    #ifdef GL_ES
    precision mediump float;
    #endif
    uniform float time;
    uniform float brightness, exposure;
    uniform float sinx, siny, fx, fy;
    uniform float invert, xsync, ysync, cinvert, colorize, r, g, b, f, ax, ay;
    uniform vec2 resolution;
    // GLSL gives us this for free... our first sampler2D automatically
    // points to our first bound texture.
    uniform sampler2D uSampler;
    
    void main() {
        // texture2D lets us lookup a pixel in a texture by passing xy values from 0â€“1
        // to get those normalized values we divide gl_FragCoord (measured in pixels) by our resolution
        vec2 p = gl_FragCoord.xy / resolution;
        vec2 offset = 1. / resolution;
        vec3 base = exposure * texture2D( uSampler, p).rgb;
        p.x = (1. - ax)* p.x + (ax * sin(p.x + f));
        p.y = (1. - ay) * p.y + (ay * sin(p.y + f));
        vec3 color = base + sin(p.x * sinx + ((fx * time) * xsync)) * sin(p.y * siny + ((fy + time) * ysync));

        vec3 final = vec3( (invert * brightness) * color);
        float rr = 1., gg = 1., bb = 1.;
        if(colorize > 0.) {
            rr = abs(r);
            gg = abs(g);
            bb = abs(b);
        }
        gl_FragColor = vec4(rr * final.x, gg * final.y, bb * final.z, 1.);
    }
</script>
<script type='text/javascript'>
    // "global" variables
    let gl, uTime, uBrightness, uExposure, uInvert, uX, uY, uXsyncx, uYsync, uFx, uFy, uF, img, texture,textureLoaded = false, program, uCinvert, uColorize, uR, uG, uB;
    let analyser, frequencyData, uAx, uAy;
    window.onload = function() {
        const canvas = document.getElementById( 'gl' )
        gl = canvas.getContext( 'webgl' )
        canvas.width = 512
        canvas.height = 512
        img = document.createElement( 'img' )
        img.crossOrigin = 'Anonymous'
        // img.src = './cat.jpg'
        // getVideo();
        img.onload = makeTexture
        document.body.appendChild( img )
        // create our canvas
        greencanvas = document.createElement( 'canvas' )
        // get a drawing context for our canvas
        greenctx = greencanvas.getContext( '2d' )
        // set our painting color
        greenctx.fillStyle = 'green'
        // draw our rectangle... 350x150 are the default canvas dimensions
        greenctx.fillRect( 0,0,350,150 )
        greenctx.fillStyle = 'red'
        greenctx.fillRect( 125,50,50,50 )
        // put the canvas on the page
        // document.body.appendChild( greencanvas )
        // define drawing area of canvas. bottom corner, width / height
        gl.viewport( 0,0,gl.drawingBufferWidth, gl.drawingBufferHeight )
        // create a buffer object to store vertices
        const buffer = gl.createBuffer()
        // point buffer at graphic context's ARRAY_BUFFER
        gl.bindBuffer( gl.ARRAY_BUFFER, buffer )
        const triangles = new Float32Array([
        -1, -1,
        1,  -1,
        -1, 1,
        -1, 1,
        1, -1,
        1, 1
        ])
        // initialize memory for buffer and populate it. Give
        // open gl hint contents will not change dynamically.
        gl.bufferData( gl.ARRAY_BUFFER, triangles, gl.STATIC_DRAW )
        // create vertex shader
        let shaderScript = document.getElementById('vertex')
        let shaderSource = shaderScript.text
        const vertexShader = gl.createShader( gl.VERTEX_SHADER )
        gl.shaderSource( vertexShader, shaderSource );
        gl.compileShader( vertexShader )
        // create fragment shader
        shaderScript = document.getElementById('fragment')
        shaderSource = shaderScript.text
        const fragmentShader = gl.createShader( gl.FRAGMENT_SHADER )
        gl.shaderSource( fragmentShader, shaderSource );
        gl.compileShader( fragmentShader )
        console.log(gl.getShaderInfoLog(fragmentShader));
        // create shader program
        program = gl.createProgram()
        gl.attachShader( program, vertexShader )
        gl.attachShader( program, fragmentShader )
        gl.linkProgram( program )
        gl.useProgram( program )
        /* ALL ATTRIBUTE/UNIFORM INITIALIZATION MUST COME AFTER 
        CREATING/LINKING/USING THE SHADER PROGAM */
        // find a pointer to the uniform "time" in our fragment shader
        uTime = gl.getUniformLocation( program, 'time' ) 
        uBrightness = gl.getUniformLocation( program, 'brightness' ) 
        uExposure = gl.getUniformLocation( program, 'exposure' ) 
        uInvert = gl.getUniformLocation(program, 'invert')
        uX = gl.getUniformLocation(program, 'sinx')
        uY = gl.getUniformLocation(program, 'siny')
        uXsync = gl.getUniformLocation(program, 'xsync')
        uYsync = gl.getUniformLocation(program, 'ysync')
        uFx = gl.getUniformLocation(program, 'fx')
        uFy = gl.getUniformLocation(program, 'fy')
        uCinvert = gl.getUniformLocation(program, 'cinvert')
        uColorize = gl.getUniformLocation(program, 'colorize')
        uR = gl.getUniformLocation(program, 'r')
        uG = gl.getUniformLocation(program, 'g')
        uB = gl.getUniformLocation(program, 'b')
        uF = gl.getUniformLocation(program, 'f')
        uAx = gl.getUniformLocation(program, 'ax')
        uAy = gl.getUniformLocation(program, 'ay')
        const uRes = gl.getUniformLocation( program, 'resolution' )
        gl.uniform2f( uRes, gl.drawingBufferWidth, gl.drawingBufferHeight )
        // get position attribute location in shader
        const position = gl.getAttribLocation( program, 'a_position' )
        // enable the attribute
        gl.enableVertexAttribArray( position )
        // this will point to the vertices in the last bound array buffer.
        // In this example, we only use one array buffer, where we're storing 
        // our vertices
        gl.vertexAttribPointer( position, 2, gl.FLOAT, false, 0,0 )
        initAudio()
        render()
    }

    function initAudio() {
        var audio = document.getElementById('myAudio');
        // navigator.mediaDevices.getUserMedia({
        //     audio:true
        // }).then( stream => { 
        //     audio.srcObject = stream
            var ctx = new AudioContext();
            var audioSrc = ctx.createMediaElementSource(audio);
            analyser = ctx.createAnalyser();
            analyser.fftSize = 2048;
            // we have to connect the MediaElementSource with the analyser 
            audioSrc.connect(analyser);
            analyser.connect(ctx.destination)
            // audio.play()
            // we could configure the analyser: e.g. analyser.fftSize (for further infos read the spec)
            
            // frequencyBinCount tells you how many values you'll receive from the analyser
            frequencyData = new Uint8Array(analyser.frequencyBinCount);
        // })
    }

    let video

    function getVideo() {
        video = document.createElement( 'video' )
        navigator.mediaDevices.getUserMedia({
            video:true
        }).then( stream => { 
            video.srcObject = stream
            video.play()
            makeTexture()
        })
        return video
    }

    function stopVideo() {
        video.pause()
        textureLoaded = false
    }

    function makeTexture() {
        // create an OpenGL texture object
        texture = gl.createTexture()
        // this tells OpenGL which texture object to use for subsequent operations
        gl.bindTexture( gl.TEXTURE_2D, texture )
        // since canvas draws from the top and shaders draw from the bottom, we
        // have to flip our canvas when using it as a shader.
        gl.pixelStorei( gl.UNPACK_FLIP_Y_WEBGL, true )
        // how to map when texture element is more than one pixel
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR )
        // how to map when texture element is less than one pixel
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR )
        // you must have these properties defined for the video texture to
        // work correctly
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE )
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE )
        // let our render loop know when the texture is ready
        textureLoaded = true;
    }
    // keep track of time via incremental frame counter
    let time = 0
    function render() {
        // schedules render to be called the next time the video card requests 
        // a frame of video
        window.requestAnimationFrame( render )
        if( textureLoaded === true ) {
            // send texture data to GPU    
            gl.texImage2D( 
            gl.TEXTURE_2D,    // target: you will always want gl.TEXTURE_2D
            0,                // level of detail: 0 is the base
            gl.RGBA, gl.RGBA, // color formats
            gl.UNSIGNED_BYTE, // type: the type of texture data; 0-255
            video             // pixel source: could also be video or image
            )
            // draw triangles using the array buffer from index 0 to 6 (6 is count)
            gl.drawArrays( gl.TRIANGLES, 0, 6 )
        } else {
            gl.texImage2D( 
            gl.TEXTURE_2D,    // target: you will always want gl.TEXTURE_2D
            0,                // level of detail: 0 is the base
            gl.RGBA, gl.RGBA, // color formats
            gl.UNSIGNED_BYTE, // type: the type of texture data; 0-255
            img             // pixel source: could also be video or image
            )
            gl.drawArrays( gl.TRIANGLES, 0, 6 )

        }
        // update time on CPU and GPU
        time++
        gl.uniform1f( uTime, time )

        // Pass control uniforms
        let brightness = document.getElementById("brightness").value / 100.0;
        let exposure = document.getElementById("exposure").value / 100.0;
        let x = document.getElementById('sinx').value;
        let y = document.getElementById('siny').value;
        let invert = document.getElementById('invert').checked;
        let xsync = document.getElementById('xsync').checked;
        let ysync = document.getElementById('ysync').checked;
        let fx = document.getElementById('fx').value;
        let fy = document.getElementById('fy').value;
        let cinvert = 0;
        let colorize = document.getElementById('colorize').checked;
        let red = document.getElementById('red').value;
        let green = document.getElementById('green').value;
        let blue = document.getElementById('blue').value;
        let ax = document.getElementById('audiox').value;
        let ay = document.getElementById('audioy').value;

        gl.uniform1f(uBrightness , brightness)
        gl.uniform1f(uExposure , exposure)
        gl.uniform1f(uInvert , invert ? -1.0 : 1.0)
        gl.uniform1f(uX , x)
        gl.uniform1f(uY , y)
        gl.uniform1f(uXsync , xsync ? 0.0 : 1.0)
        gl.uniform1f(uYsync , ysync ? 0.0 : 1.0)
        gl.uniform1f(uFx , fx)
        gl.uniform1f(uCinvert , cinvert)
        gl.uniform1f(uColorize , colorize ? 1.0 : 0.0)
        gl.uniform1f(uR , red / 256.0)
        gl.uniform1f(uG , green / 256.0)
        gl.uniform1f(uB , blue / 256.0)
        console.log(analyser.getByteFrequencyData(frequencyData));
        document.getElementById("audioInfo").innerHTML = frequencyData[1] / 200.0;
        gl.uniform1f(uF , frequencyData[1] / 200.0)
        gl.uniform1f(uAx , ax / 100.0)
        gl.uniform1f(uAy , ay / 100.0)
        // draw triangles using the array buffer from index 0 to 6 (6 is count)
        gl.drawArrays( gl.TRIANGLES, 0, 6 )
    }
</script>
</html>